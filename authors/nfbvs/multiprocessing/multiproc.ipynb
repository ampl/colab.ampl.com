{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RjB1ipC7KbS"
   },
   "source": [
    "# AMPL - solve multiple models in parallel\n",
    "[![multiproc.ipynb](https://img.shields.io/badge/github-%23121011.svg?logo=github)](https://github.com/ampl/colab.ampl.com/blob/master/authors/nfbvs/multiprocessing/multiproc.ipynb) [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ampl/colab.ampl.com/blob/master/authors/nfbvs/multiprocessing/multiproc.ipynb) [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/ampl/colab.ampl.com/blob/master/authors/nfbvs/multiprocessing/multiproc.ipynb) [![Gradient](https://assets.paperspace.io/img/gradient-badge.svg)](https://console.paperspace.com/github/ampl/colab.ampl.com/blob/master/authors/nfbvs/multiprocessing/multiproc.ipynb) [![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/ampl/colab.ampl.com/blob/master/authors/nfbvs/multiprocessing/multiproc.ipynb) [![Hits](https://h.ampl.com/https://github.com/ampl/colab.ampl.com/blob/master/authors/nfbvs/multiprocessing/multiproc.ipynb)](https://colab.ampl.com)\n",
    "\n",
    "Description: Solve multiple AMPL models in parallel in Python with amplpy and the multiprocessing modules.\n",
    "\n",
    "Tags: AMPL, Python, amplpy, multiprocess, Parallel Computing, Stochastic Programming\n",
    "\n",
    "Notebook author: Nicolau Santos <<nfbvs@ampl.com>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rQ50dBwL7KbX"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install -q amplpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101,
     "referenced_widgets": [
      "5c52a4f288924ca8bbf5182a951af6a8",
      "5a786f2dd2584199a4001c8bebefd757",
      "9a901424b8c04687b39b5e1251ee3919",
      "fcf080abd68144728d12fa81f879d5d5",
      "b2d8e84e2f6545bc98bbaf40294b9ad8",
      "de8c25d11df34ae2b86964266defdfdc",
      "a1e4bcf9de474b4f835419c6278d4e42",
      "45de4f35c7f04c37b87cad70c3e3b224",
      "59a30522756c4d668323600e0800a022",
      "4510b5e780f24d44ace00a42c38cf6dc",
      "5bec63a60fab4e628b18b6576859f23d",
      "4cfacef2f3e44067b81ac133fe17ae5b",
      "c9f8c186dbec4424895eb43630e458f2",
      "a0a3a52262a340debb5a29ce65170164"
     ]
    },
    "id": "s7DEaRp87KbY",
    "outputId": "7ccc087a-1af8-445e-c56d-31f3371b0c38"
   },
   "outputs": [],
   "source": [
    "# Google Colab & Kaggle integration\n",
    "from amplpy import AMPL, ampl_notebook\n",
    "\n",
    "ampl = ampl_notebook(\n",
    "    modules=[\"highs\"],  # modules to install\n",
    "    license_uuid=\"default\",  # license to use\n",
    ")  # instantiate AMPL object and register magics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "A common task is to analyze the results of a model given different combinations of some input parameters. This can be done in parallel with [amplpy](https://amplpy.ampl.com/en/latest/) and the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html) module.\n",
    "\n",
    "For our demonstration we will use a [stochastic programming](https://github.com/ampl/colab.ampl.com/blob/master/authors/nfbvs/newsvendor/newsvendor.ipynb)\n",
    "model available at\n",
    "https://colab.ampl.com/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model.mod\n",
    "\n",
    "param samples > 0;\n",
    "param demand{1..samples} >= 0;\n",
    "param cost > 0;\n",
    "param recover < cost;\n",
    "param retail >= 0;\n",
    "param minrev;\n",
    "param maxrev;\n",
    "param alpha >= 0, <= 1;\n",
    "param beta >= 0, <= 1;\n",
    "\n",
    "var nu >= minrev, <= maxrev;\n",
    "var excess{1..samples} >= 0, <= maxrev - minrev;\n",
    "var order >= 0;\n",
    "var sales{i in 1..samples} >= 0, <= demand[i];\n",
    "var discount{1..samples} >= 0;\n",
    "var profit{1..samples} >= minrev, <= maxrev;\n",
    "\n",
    "var cvar = nu + 1 / ((1 - alpha) * samples) * sum{i in 1..samples} excess[i];\n",
    "var average_profit = (1/samples) * sum{i in 1..samples} profit[i];\n",
    "\n",
    "maximize prof:\n",
    "    - beta * cvar + (1-beta) * average_profit;\n",
    "\n",
    "s.t. c1 {i in 1..samples}: profit[i] == -cost * order + retail * sales[i] + recover * discount[i];\n",
    "s.t. c2 {i in 1..samples}: sales[i] + discount[i] == order;\n",
    "s.t. c3 {i in 1..samples}: -profit[i] - nu <= excess[i];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has three parameters of major interest for our example, namelly:\n",
    "- alpha - parameter to manage the conditional value at risk (CVaR)\n",
    "- beta - parameter that manages the contribution of the CVaR and average profit to the objective function \n",
    "- demand - unknown parameter for which we will generate multiple scenarios.\n",
    "\n",
    "Our main objective is to study the impact of different alpha and beta combinations for different  scenarios of the demand.\n",
    "\n",
    "## Implementation\n",
    "\n",
    "First we create a worker function that:\n",
    "- gets as input a list with the values of alpha, beta, run and seed\n",
    "- generate data for the demand parameter using the given seed\n",
    "- instantiates an AMPL object and loads the data, including the provided alpha and beta values\n",
    "- solves the problem and returns a list with the initial alpha, beta and run parameters and also the obtained objective value and used wall time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile worker.py\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "from amplpy import AMPL\n",
    "\n",
    "\n",
    "# Define constants\n",
    "# Economic parameters\n",
    "cost = 2\n",
    "retail = 15\n",
    "recover = -3\n",
    "# Parameters to generate data in each process\n",
    "samples = 10000\n",
    "sigma = 100\n",
    "mu = 400\n",
    "\n",
    "def worker(data):\n",
    "    \"\"\"\n",
    "    Example worker\n",
    "    Input: a list with parameters\n",
    "        alpha - parameter to be passed to AMPL\n",
    "        beta - parameter to be passed to AMPL\n",
    "        run - number of the run for the alpha and beta combination\n",
    "        seed - seed to generate data for the given process\n",
    "    Output: a list with parameters\n",
    "        alpha - parameter used in the run\n",
    "        beta - parameter used in the run\n",
    "        run - number of the run for the alpha and beta combination\n",
    "        obj - objective value of the solved model\n",
    "        worker_time - wall time used by the worker\n",
    "    This function as the following steps: \n",
    "        generate data acording to the received parameters\n",
    "        instantiate AMPL and load an existing model file\n",
    "        solve the model with the defined solver\n",
    "        output results\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Get information from the input list\n",
    "    alpha = data[0]\n",
    "    beta = data[1]\n",
    "    run = data[2]\n",
    "    seed = data[3]\n",
    "\n",
    "    # Initialyze and seed random number generator\n",
    "    rng = random.Random()\n",
    "    rng.seed(seed)\n",
    "\n",
    "    # Generate data for this execution\n",
    "    demand = [max(rng.normalvariate(mu,sigma), 0) for i in range(samples)]\n",
    "    maxrev = max(demand) * (retail - cost)\n",
    "    minrev = max(demand) * (recover - cost) + min(demand) * retail\n",
    "\n",
    "    # Create AMPL instance and load the model\n",
    "    ampl = AMPL()\n",
    "    ampl.read(\"model.mod\")\n",
    "\n",
    "    # Load the data\n",
    "    ampl.param[\"samples\"] = samples\n",
    "    ampl.param[\"cost\"] = cost\n",
    "    ampl.param[\"recover\"] = recover\n",
    "    ampl.param[\"retail\"] = retail\n",
    "    ampl.param[\"minrev\"] = minrev\n",
    "    ampl.param[\"maxrev\"] = maxrev\n",
    "    ampl.param[\"demand\"] = demand\n",
    "    ampl.param[\"alpha\"] = alpha\n",
    "    ampl.param[\"beta\"] = beta\n",
    "\n",
    "    # Set solver and options\n",
    "    ampl.option[\"solver\"] = \"highs\"\n",
    "    ampl.option[\"highs_options\"] = \"tech:threads=1\"\n",
    "    # Solve without generating any output\n",
    "    # use this when your model is ready for deployment\n",
    "    # otherwise use the regular solve (commented below) to track potential issues\n",
    "    ampl.get_output(\"solve;\")\n",
    "    #ampl.solve()\n",
    "\n",
    "    # Get results\n",
    "    obj = ampl.obj[\"prof\"].value()\n",
    "\n",
    "    worker_time = time.time() - start_time\n",
    "    return [alpha, beta, run, obj, worker_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "In our case the model will be the same for every run. However, it's possible to pass the name of the model as a parameter to the worker function and solve different models in parallel.\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "Note that the chosen solver may use by default more than one process/thread. Unless you are configuring the number of AMPL and solver processes manually you should set the number of processes/threads of the solver to 1.\n",
    "</div>\n",
    "\n",
    "Afterwards we create a list with the different parameter combinations that we will send as input for each process.\n",
    "\n",
    "Parallelization is obtained with the [multiprocessing](https://docs.python.org/3/library/multiprocessing.html)  module: we create a multiprocessing pool with a given number of processors and we map the created pool to the worker function and the list with the different parameter combinations.\n",
    "\n",
    "At the end we print the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurations:\n",
      "alpha\tbeta\trun\tseed\n",
      "0.7\t0.6\t0\t0\n",
      "0.7\t0.6\t1\t1\n",
      "0.7\t0.6\t2\t2\n",
      "0.7\t0.7\t0\t3\n",
      "0.7\t0.7\t1\t4\n",
      "0.7\t0.7\t2\t5\n",
      "0.8\t0.6\t0\t6\n",
      "0.8\t0.6\t1\t7\n",
      "0.8\t0.6\t2\t8\n",
      "0.8\t0.7\t0\t9\n",
      "0.8\t0.7\t1\t10\n",
      "0.8\t0.7\t2\t11\n",
      "\n",
      "Number of workers: 12\n",
      "\n",
      "4 processors available\n",
      "\n",
      "Results:\n",
      "alpha\tbeta\trun\tobjective\tworkertime\n",
      "0.7\t0.6\t0\t3525.832209279827\t25.238504648208618\n",
      "0.7\t0.6\t1\t3524.356178682977\t25.41237211227417\n",
      "0.7\t0.6\t2\t3541.325355197152\t25.553394317626953\n",
      "0.7\t0.7\t0\t3565.9342984444384\t27.238896131515503\n",
      "0.7\t0.7\t1\t3585.2380403500324\t21.48252558708191\n",
      "0.7\t0.7\t2\t3402.66236960429\t20.380152225494385\n",
      "0.8\t0.6\t0\t3265.1446466955886\t20.773118257522583\n",
      "0.8\t0.6\t1\t3390.28915038965\t20.527676343917847\n",
      "0.8\t0.6\t2\t3422.6281549721944\t19.438149213790894\n",
      "0.8\t0.7\t0\t3290.5810949315205\t20.264755964279175\n",
      "0.8\t0.7\t1\t3233.292842109562\t17.839205741882324\n",
      "0.8\t0.7\t2\t3282.2282040925375\t18.890254974365234\n",
      "\n",
      "Main time: 66.715\n",
      "Average worker time: 65.760\n",
      "Total time: 263.039\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example of multiprocessing with Python and amplpy.\n",
    "This module defines a worker function that solves an AMPL model.\n",
    "Multiple combination of parameters are generated and each one is\n",
    "passed to a process.\n",
    "Individual results of all processes are printed at the end.\n",
    "\"\"\"\n",
    "\n",
    "import multiprocessing\n",
    "import os\n",
    "import time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from worker import worker\n",
    "\n",
    "    # Generate different combinations of parameters to send to each process\n",
    "    alphas = [0.7, 0.8]\n",
    "    betas = [0.6, 0.7]\n",
    "    nruns = 3\n",
    "\n",
    "    config = []\n",
    "    seed = 0\n",
    "    for a in alphas:\n",
    "        for b in betas:\n",
    "            for r in range(nruns):\n",
    "                config.append((a, b, r, seed))\n",
    "                seed += 1\n",
    "\n",
    "    print(\"Configurations:\")\n",
    "    print(\"\\t\".join([\"alpha\", \"beta\", \"run\", \"seed\"]))\n",
    "    for c in config:\n",
    "        print(\"\\t\".join([str(i) for i in c]))\n",
    "    print()\n",
    "    print(\"Number of workers:\", len(config))\n",
    "    print()\n",
    "\n",
    "    # Get the number of processors available and initialyze the pool\n",
    "    # Could be better to use nproc = os.cpu_count()-1 and keep one processor for the OS\n",
    "    nproc = os.cpu_count()\n",
    "    print(nproc, \"processors available\")\n",
    "    print()\n",
    "    pool = multiprocessing.Pool(nproc)\n",
    "\n",
    "    # Run the workers\n",
    "    main_start_time = time.time()\n",
    "    results = pool.map(worker, config)\n",
    "    pool.close()\n",
    "    main_end_time = time.time()\n",
    "\n",
    "    # Print results\n",
    "    print(\"Results:\")\n",
    "    print(\"\\t\".join([\"alpha\", \"beta\", \"run\", \"objective\", \"workertime\"]))\n",
    "    for r in results:\n",
    "        print(\"\\t\".join([str(i) for i in r]))\n",
    "    print()\n",
    "    print(\"Main time: %.3f\" % (main_end_time - main_start_time))\n",
    "    print(\"Average worker time: %.3f\" % (sum(r[4] for r in results) / (nproc)))\n",
    "    print(\"Total time: %.3f\" % (sum(r[4] for r in results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example a nearly linear speedup was achieved. Depending on the ratio between the number of workers and number of processes this value may vary.\n",
    "Statistical analysis of the results is beyond the scope of this notebook."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee4198aac13dae9b6fccd443041680d99c2643c4956ef7c80ff6dcc0057cb523"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "4510b5e780f24d44ace00a42c38cf6dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "45de4f35c7f04c37b87cad70c3e3b224": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cfacef2f3e44067b81ac133fe17ae5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59a30522756c4d668323600e0800a022": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a786f2dd2584199a4001c8bebefd757": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de8c25d11df34ae2b86964266defdfdc",
       "IPY_MODEL_a1e4bcf9de474b4f835419c6278d4e42"
      ],
      "layout": "IPY_MODEL_45de4f35c7f04c37b87cad70c3e3b224"
     }
    },
    "5bec63a60fab4e628b18b6576859f23d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c52a4f288924ca8bbf5182a951af6a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a786f2dd2584199a4001c8bebefd757",
       "IPY_MODEL_9a901424b8c04687b39b5e1251ee3919",
       "IPY_MODEL_fcf080abd68144728d12fa81f879d5d5"
      ],
      "layout": "IPY_MODEL_b2d8e84e2f6545bc98bbaf40294b9ad8"
     }
    },
    "9a901424b8c04687b39b5e1251ee3919": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_c9f8c186dbec4424895eb43630e458f2",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Using existing license.\n"
        ]
       }
      ]
     }
    },
    "a0a3a52262a340debb5a29ce65170164": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1e4bcf9de474b4f835419c6278d4e42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "UUID:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_5bec63a60fab4e628b18b6576859f23d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4cfacef2f3e44067b81ac133fe17ae5b",
      "value": ""
     }
    },
    "b2d8e84e2f6545bc98bbaf40294b9ad8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9f8c186dbec4424895eb43630e458f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de8c25d11df34ae2b86964266defdfdc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "",
      "description": "Use existing license",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_59a30522756c4d668323600e0800a022",
      "style": "IPY_MODEL_4510b5e780f24d44ace00a42c38cf6dc",
      "tooltip": ""
     }
    },
    "fcf080abd68144728d12fa81f879d5d5": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_a0a3a52262a340debb5a29ce65170164",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Licensed to Default AMPL Community Edition License for the AMPL Model Colaboratory.\n"
        ]
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
